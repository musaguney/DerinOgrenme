{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE_E-QDzs2Rj",
        "outputId": "32a288f7-5c70-4953-a318-ac6ca0a76cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "VdaUxyM0s7Zr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.max_pool2d(x, 2, 2)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 32 * 56 * 56)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HlRTY6bGs8z2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    data_transform = datasets.ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/Pneumonia/X-Ray', transform=transform)\n",
        "\n",
        "    train_size = int(0.75 * len(data_transform))\n",
        "    val_size = int(0.15 * len(data_transform))\n",
        "    test_size = len(data_transform) - train_size - val_size\n",
        "\n",
        "    train_data, val_data, test_data = torch.utils.data.random_split(data_transform, [train_size, val_size, test_size])\n",
        "\n",
        "    extra_val_data, train_data = torch.utils.data.random_split(train_data, [int(0.1 * len(train_data)), len(train_data) - int(0.1 * len(train_data))])\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=32)\n",
        "    test_loader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "metadata": {
        "id": "bNsh_Hrss-0G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_cnn(model, train_loader, val_loader, test_loader, epochs=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    train_accuracy_list = []\n",
        "    val_accuracy_list = []\n",
        "    test_accuracy_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train, correct_train = 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        total_val, correct_val = 0, 0\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct_val / total_val\n",
        "        val_accuracy_list.append(val_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        total_test, correct_test = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_test += labels.size(0)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct_test / total_test\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "    return train_accuracy_list, val_accuracy_list, test_accuracy_list"
      ],
      "metadata": {
        "id": "UnkOYiKbtA-w"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader = load_data()\n",
        "cnn_model = CNN()\n",
        "train_acc_list, val_acc_list, test_acc_list = train_evaluate_cnn(cnn_model, train_loader, val_loader, test_loader)"
      ],
      "metadata": {
        "id": "7VVyuz14u7Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Accuracies: {train_acc_list}\")\n",
        "print(f\"Validation Accuracies: {val_acc_list}\")\n",
        "print(f\"Test Accuracies: {test_acc_list}\")"
      ],
      "metadata": {
        "id": "SSFteV-wtKxZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}